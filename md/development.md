# 퀀트 개발

## 1.기본 개념

### 투자 성과 지표

* 연평균 복리수익률(CAGR)

  ![img](file:///C:\Users\enjon\AppData\Local\Temp\DRW0000455c2bbd.gif)  

* 최대 낙폭(MDD)

최대 낙폭 = (Trough Value - Peak Value) / Peak Value

* 변동성

  ![img](file:///C:\Users\enjon\AppData\Local\Temp\DRW0000455c2bc1.gif)  

* 샤프 지수

### 평균 회귀 전략

* 볼린저 밴드

### 듀얼 모멘텀 전략



### 가치 투자 전략





## 2.고급 개념





## 3.기본 개발

### 1.데이터 수집

#### 1.오픈 API 사용*

##### FinanceDataReader

pandas-datareader의 불안정성을 보완하고자 만든 API

거래소별 전체 종목 코드 : StockListing()

가격데이터 : DataReader()

관련 API 사용자 메뉴얼 : https://github.com/FinanceData/FinanceDataReader/wiki/Users-Guide

~~~python
jp_df1 = fdr.DataReader(symbol='7751',start='2019-01-01',exchange='TSE')

jp_df1['Close'].plot()
~~~

![image-20211122145228175](C:\Users\enjon\AppData\Roaming\Typora\typora-user-images\image-20211122145228175.png)

거래소, 종목코드, 시작일 등 옵션을 주어 데이터를 불러와 그래프 그릴 수 있다.

##### Quandl(경제 지표 데이터)

세계시장 및 경제 지표 데이터를 얻을 수 있다.

무료 데이터와 유료 데이터가 구분된다. 

##### FRED



##### 통계청



##### 노동청

https://www.bls.gov/data/ 에서 데이터셋 다운.



##### CRSP(증권가격 연구센터)

1926년부터 미국의 모든 상장 주식의 종가, 거래량, 상장 주식 등 거래 데이터를 시카고 대학에서 생성, 관리 중이다. 

https://crsp.org/



#### 2.증권 API 이용

대신증권, 이베스트증권 등 몇개의 증권사에서만 제공.

github.com/quantylab/rltrader/blob/master/creon.py 참조

#### 3.웹 크롤링

1.google finance

pandas-datareader를 이용. but 안정적이지 않아 권장하지 않음.

2.yahoo finance

fix_yahoo_finance API 지원이 중단되면서 해당 API는 크롤링방식으로 변경해 제공

3.금융포털(investing.com/네이버 금융/yahoo finance 등)

해당 사이트 링크/robots.txt를 통해 크롤링 가능한 경로 확인.

많은 데이터를 가져오는데 제한적

4.데이터 요청

RLTrader Github에서 데이터 요청

#### 4.데이터 구매





### 2.데이터 가공 & 전처리

* 가공 : 필요한 영역만의 데이터 선택



* 결측치(NaN), 이상치(inf, 범위 초과 값...) 처리법

1.df[df.isin([np.nan, np.inf, -np.inf]).any(1)]

2.

3.

* 벡터화, 정규화, 특성 추출 등

* 전처리 과정에서 주의할 점

금융 데이터는 노이즈가 심하고 특성 수에 비해 상대적으로 시계열 데이터 길이가 짧다. 더 자세히 말하면, 일반적으로 주가 모델링은 기하 브라운 모형(GBM)을 가정하는데, 이는 자기 회귀 모형(AR)과 거의 동일하다. 내일의 주가를 영향을 미치는 요소가 오늘의 주가, 정보, 노이즈라 할 수 있는데 여기서 정보의 영향이 너무 작기 때문에 결과적으로 예측 모델을 이용하면 현재 값이 다음 값에 대한 최선의 예측값이 된다.

노이즈를 제거하는 전처리와 많은 변수의 타임 프레임을 맞추는 전처리 작업이 중요하다.

#### 노이즈 줄이는 법

노이즈 제거란 불필요한 데이터를 없애 중요한 정보에 주목하는 것 이다.

##### SVD(특이값 분해)

 흔히 정보 압축이나 차원 축소 방법 사용. 사실 노이즈 제거는 신호처리나 이미지 처리에서 많이 사용. 문제는 해당 분야에서 효과적인 노이즈 제거 방식은 금융 시계열에서는 큰 효과를 내지 못하는 경우가 많다. 그럼에도 노이즈 제거하기 위한 많은 방법이 시도되고 있다. 몇 가지를 소개하려 한다. 

##### 이동 평균과 지수 이동 평균

지수 이동 평균은 특정 기간의 주가 중 최근 가격에 더 큰 가중치를 두어 계산.

##### 웨이블릿 변환

웨이블릿 기저함수를 이용해 데이터를 변환하는 것을 말한다. 여기서 웨이블릿 기저함수는 적분하면 0이 되고 진동하면서 진폭이 0으로 수렴하는 함수를 말한다. 즉 웨이블릿이란 0을 중심으로 증가와 감소를 반복하는 파동과 같은 진동을 말한다. 웨이블릿 변환은 신호를 근사값과 세부값으로 구분한다. 근사값은 신호의 저주파 성분을 담고, 세부값은 신호의 고주파 성분을 담는다. 그리고 찾은 근사값을 다시 반으로 나눠 근사값과 세부값으로 구분한다. 이런 특징으로 웨이블릿은 데이터 압축에도 사용할 수 있다. 

##### PCA(주성분 분석)를 이용한 노이즈 제거

PCA는 여러 데이터가 모여 하나의 분포를 이룰 때 이 분포의 주성분을 분석하는 방법. 주성분이란 그 방향으로 데이터들의 분산이 가장 큰 방향 벡터를 의미한다. 즉 주성분만으로 충분히 표현 가능하기 때문에 부차적 요소를 제거할 수 있다는 장점이 있다. PCA 알고리즘은 PCA를 통해 반환된 각각의 주성분 해석하기 어려운 단점이 있어 해석력이 필요한 금융 데이터 분석에서는 권장하지 않는다.

##### 딥러닝 기반의 노이즈 제거 - 오토인코더

Autoencoder는 딥러닝에서 차원 축소할 때 기본적으로 사용하는 방법이다. 활성화 함수로 sigmoid,  ReLU같은 비선형 함수 대신 선형 함수를 사용하고, 손실 함수로 평균제곱오차(MSE)를 사용할 경우 PCA와 동일하다고 볼 수 있다. 다양한 적층 오토인코더(SAE)를 활용해 데이터의 노이즈를 제거하고 입력으로 사용해 좋은 성과를 냈다는 많은 논문과 자료를 확인할 수 있다. 



### +코드관련

모듈 : xxx.py같이 전역변수, 함수, 클래스 등을 모아둔 파일. 파일명이 곧 모듈명이다. 

패키지 : 모듈을 디렉토리 형식으로 묶어 놓은 것.





## 4.고급 개발

### 3-1.머신 러닝

#### 지도 학습

##### SVM(support vector machine)

하드웨어가 덜 발달 됐던 시절 딥러닝보다 성능이 좋았던 알고리즘.

* 장점

-데이터의 특성이 많지 않아도 상대적으로 좋은 성능을 낼 수 있다.

* 단점

데이터가 많을 시 속도, 메모리 관점에서 불리.

데이터 전처리와 매개변수 설정에 신경을 많이 써야 한다. 

해석 가능성이 약하다. 



#### 트리 기반 모델

##### Random forest(배깅계열)

  트리는 깊어질수록 편향이 작지만 분산이 커진다. 하지만 분산이 큰 각 트리의 평균을 취해주면 편향을 유지하면서 분산을 줄여 과적합을 보완한다. 중요한 것은 트리들의 상관관계를 줄여야 모델의 정확도가 높아진다는 것. 전처리 작업에서 상관계수가 높은 변수들을 걸러주는  것이 좋다. 

  일반적인 성능이 매우 뛰어나고, 매개변수 튜닝을 많이 하지 않아도 잘 작동하며 데이터의 스케일 조정이 필요 없다. CPU 코어가 많다면 병렬 처리도 손쉽게 할 수 있고, 특성 중요도를 계산할 수 있기 때문에 전략에 대한 해석 가능성을 높여준다. OOB(out-of-bags)데이터를 검증에 사용할 수 있다는 장점이 있지만, 주기성이나 경향성이 있는 데이터에서 선능이 떨어지는 경향이 있다. 또한 차원이 높고 희소한 데이터(예-텍스트 데이터)에는 잘 작동하지 않다.

  이런 단점에도 시장 데이터 예측이나 주가 종목 선택 문제에 많이 활용. 다양한 분류 알고리즘을 비교한 논문에도 랜덤 포레스트가 가장 좋은 성능을 언급. (Ballings, michel, et al. [Evaluating multiple cassifiers for stock price direction prediction.]) 그리고 주식 시장 예측 문제를 다룬 머신러닝 지도 학습 알고리즘을 분석한 논문에서는 랜덤 포레스트가 규모가 큰 데이터셋에서 가장 뛰어난 성능을 보인다는 결과를 내놓기도 했다.(Kumar, Indu, et al. [A comparative study of supervised machine learning algorithms for stock market trend prediction.]) 로페즈 교수는 PCA를 사용해 차원을 축소한 후 랜덤 포레스트에 적합하는 방법을 권장했다([Advances in financial machine learning]-John Wiley & Sons, 2018)

##### 부스팅(계열)

  약한 분류기를 결합해 강한 분류기를 만드는 과정을 일컫는다. 약한 분류기를 결합할 때 틀린 것에 가중치를 부여하며 강한 학습기를 만들어간다. 가중치를 부여하는 방식에 따라 분류 알고리즘이 달라진다. 그래디언트 부스팅 알고리즘(GBDT)는 경사 하강법을 사용한다. XGBoost, LightGBM이 이에 속한다.

  부스티 계열의 알고리즘은 테이블 형식의 데이터에서 매우 뛰어난 성능을 보여준다. XGBoost, LightGBM, CatBoost가 널리 쓰이고 있다. 

* 금융에서 부스팅과 배깅

부스팅은 오답에 높은 가중치를 부여하고 정답에 낮은 가중치를 부여해 오답에 더욱 집중하도록 하기 때문에 편향, 과소적합 문제를 훌륭하게 처리할 수 있는 장점이 있다.  그러나 편향을 교정하면 과적합을 일으킬 위험성이 커진다. 반면 배깅의 장점은 분산을 감소시킨다.

  금융데이터는 낮은 신호-노이즈 비율로 인해 모델을 과적합하는 일이 자주 일어나기 때문에 과적합은 과소적합보다 더 큰 문제가 될 수 있다. 따라서 금융에서는 부스팅보다 배깅계열을 더 선호한다는 주장이 있다. 또한 부스팅은 이상치에 취약하고 계산 속도가 배깅보다 더 느리다는 단점이 있다.

#### 비지도 학습

##### 차원 축소



##### 클러스터링



#### 교차 검증

다양한 방식들 존재. holdout 방법, one leave out 방법, k-fole 방법 등...

일반적으로 이러한 방법들은 시간적 요소가 포함된 시계열 데이터에 적합하지 않다는 의견이 많다. 시계열 데이터는 시간 축과 강한 상관관계를 가지는데 시간 축에는 명확한 순서가 있다. 202년 데이터를 사용해 훈련 후 18년 주가를 예측하는데 사용하면 안된다.사전 관찰 편향을 일으킬 수 있어 이를 해결하기 위해 다양한 방법중 일반적으로 walk-forward 교차 검증 방법이 있다.

##### walk-forward 교차 검증과 blocking walk forward 교차 검증

walk-forward 교차 검증은 사이킷런의 timesplit()함수로 쉽게 구현할 수 있다. 하지만 이 방식을 이용해도 데이터 leakage을 피할 수 없어 blocking walk-forward 교차 검증 방법을 사용하기도 한다. 이 방식은 margin을 설정한다.

> data leagkage란?  다시 정리하기**************
>
> target leakage와 train-test contamination이 있다.

* embargo & purging

train set과 test set 사이에 margin을 둬서, 각 검증 단계에서 사용하는 train set이 겹치지 않도록 설정한다. 하지만 시계열이 짧은 경우 좋은 성능을 내지 못할 확률이 크다. 많은 블로그에서 로페즈 교수가 자신의 책에서 소개한 purging, embargo를 접목한 교차 검증 방법이 많이 언급되나, 실증적으로 더 좋은 효과가 증명되지는 않았다. 이론적으로는 사전 관찰 편향을 피할 수 있지만, 아직 이 방법이 통용되지는 않는다. 

embargo방식은 test set 뒤에 더 넓은 margin을 추가해 leakage를 방지한다. 해당 교차 검증 방법은 mlfinlab이라는 라이브러리를 이용하면 쉽게 구현할 수 있다.

시계열데이터, 특히 금융 시계열에서 좋은 성능을 낼 수 있는 교차 검증 방법은 heuristic하게 여러가지를 시도하는 수밖에 없다. 교차 검증 목적은 우리가 훈련시킨 모델이 일반화 능력을 가질 수 있게 만드는 것이다. 하지만 데이터 자체에 노이즈가 많거나 입력으로 사용한 변수가 유용하지 못하면 아무리 좋은 교차 검증 방법을 사용해도 신뢰할 만한 결과를 얻기 힘들다.

#### 코드

Scikit-learn을 통해 머신러닝 알고리즘 구현을 하면 편하다.



###  3-2.Deep learning

부스팅 계열 알고리즘에 해당.

#### 머신러닝과 비교

##### 장점

* 특성공학

가장 큰 차이점은 특성공학과 관련된 부분이다. 딥러닝은 사람이 찾아야 할 목적에 적합한 특성을 사람 대신 자동으로 찾아준다. 예로 개, 고양이를 분류할 때, 머신러닝은 특성을 직접 정해서 학습시키지만, 딥러닝은 이미지 데이터만을 제공해 학습하고 특성을 추출하게 한다. 

* 단순함

전통적인 머신러닝은 문제 해결 시 주로 문제를 여러 조각으로 쪼개고, 각각에 대한 해답을 구해 병합하는 방법을 사용. 딥러닝을 바로 해답을 구하는 방식이다. 

* 다용도와 재사용성

딥러닝은 추가되는 데이터로도 훈련할 수 있다. 사전에 학습된 모델의 가중치를 새로운 모델에 적용하거나, 사전 학습된 ConvNet의 마지막 '완전 연결층'만 변경해 분류를 실행할 수 있는 '전이 학습'이 가능하다. 



##### 단점

* 하드웨어 의존도가 높다
* 데이터 의존도가 높다
* 실행 시간이 길다
* 해석력이 약하다



#### 금융데이터 분석에 DL을 사용해야 하는 이유

마이크로소프트의 데이터 과학자 프란체스카 라제리는 딥러닝을 시계열 분석에 사용해야 하는 이유를 3가지 들었다.

1.딥러닝은 정제되지 않거나 불완전한 데이터로부터 자동으로 특성을 학습하고 추출할 수 있다. 많은 경우에 딥러닝 모델은 노이즈가 섞인 입력에 견고한 경향을 보이기 때문에 좋은 선택지가 될 수 있다. 추가적으로, 오토인코더나 GAN같은 생성 모델은 입력 데이터를 '표현벡터'같은 압축 데이터로 만들어 새로운 특성으로 사용할 수 있다. NLP에서 자주 사용하는 embedding방법도 대표적인 특성 추출의 예라고 볼 수 있다. 즉 딥러닝은 사람이 뽑아내기 힘들거나 애매한 특성을 추출하는데 능하기 때문에 '시간'이라는 요소가 포함되어 예측하기 어려운 시계열 데이터에서도 좋은 성능을 낼 것이라고 믿는 연구자들에 의해 연구가 진행되고 있다. 확실한 성과를 확보하기 위해서는 더 엄밀한 가정과 신중한 검증 방법, 고도의 도메인 지식이 필요하다.

2.딥러닝은 다중 입력과 출력을 지원한다. 시계열 데이터 분석에서 다양한 방식의 입력/출력을 지원한다는 점은 매우 중요. 이런 기능도 머신러닝에서 구현할 수 있지만, 딥러닝은 이러한 프로세스가 더 쉽게 만들어 준다.

3.딥러닝 네트워크는 비교적 길이가 긴 시퀀스에 걸쳐있는 패턴을 추출하는 데 탁월하다. RNN 모델은 시퀀스 데이터를 다루는 성능이 좋다고 알려졌다. RNN은 학습할 때 현재 와 과거 입력값을 함께 고려하기 때문에 시계열 데이터를 학습하기에 적합하다. 



#### 알고리즘

딥러닝 모델은 저마다 어떤 가정에서 만들어 지는데, 그래서 각 모델의 가정을 파악하고 데이터 특성에 맞는 모델을 선택하는 것이 중요하다.

##### CNN(Convolution neural network, 합성곱 신경망)

CNN은 이미지 인식이나 분류 문제에서 탁월한 성능을 보인다. 그 이유는 합성곱층의 목적이 입력 이미지에서 특성을 추출하는 것이다. 

AlexNet 논문을 살펴보면 이미지의 특성에 대한 CNN의 가정으로 정상성과 픽셀의 종속성이다. '정상성'은 시계열 데이터의 통계적 특성이 시간이 지나도 변하지 않는다는 뜻이고, '픽셀의 종속성'은 이미지에서 한 점과 의미 있게 연결된 점들은 주변에 있는 점들로만 국한된다는 뜻이다. 여기서 말하는 정상성은 시간에 대한 정상성이 나리아 위치에 대한 정상성인데 쉽게 말해 위치에 관계 없이 동일한 패턴들이 반복되는 특성을 잡아낼 수 있다. 즉 이미지의 특정 위치에서 학습한 파라미터를 이용해 다른 위치에 있는 동일한 특성을 추출할 수 있다는 뜻이다. 

여러 특성을 구별하기 위해 필요한 것이 '파라미터 공유'방법이다. 파라미터 공유는 '특성지도(feature map)' 하나로 출력하기 위해 필터를 단 한 장만 유지하기 때문에 완전 연결층보다 훨씬 더 적은 파라미터 개수를 사용해 메모리를 아낄 수 있어 연산량이 적고 통계적 효율 또한 향상된다. 

'이동 불변성'특징이 있다. 완전 연결 네트워크에서는 새로운 위치에 나타난 것은 새로운 패턴으로 학습해야 하지만, 이동 불변성 덕분에 입력의 위치가 변해도 출력이 변하지 않는다. 즉 강아지를 인식할 때 이미지의 어디에 위치하든 상관없이 같은 결과를 출력한다는 의미이다. 뿐만 아니라 'locality'가정(작은 지역 안에 픽셀 종속성이 있다는 가정)은 수용 영역과 유사한 local 정보를 활용할 수 있게 해준다. 공간적으로 인접한 신호들에 대한 correlation을 비선형 필터를 적용해 추출하는데 이러한 필터를 여러 개 적용하면 다양한 로컬 특징을 추출해낼 수 있다. 이렇게 CNN은 이미지 데이터로부터 문제 해결을 위한 복잡하고 추상적인 시각적 개념을 효과적으로 추출하는데, 이를 '표현학습'이라고 한다.

CNN은 raw input data로 부터 복잡하고 추상적인 시각적 개념을 효과적으로 추출하는 특징은 시계열 예측 문제에도 적용될 수 있다. 관측치 시퀀스를 CNN 모델이 읽고 정제할 수 있는 1차원 이미지처럼 만들면 된다.(신호처리 영역에서는 이미 오래전부터 1D-합성곱을 사용했다) 이러한 방법은 무선 센서 강도 데이터를 활용해 사물의 위치와 모션을 예측하는 문제에도 적용되어 좋은 효과를 거두었다. 

금융 시계열 예측을 하기 위해 1D-합성곱을 써도 되고, 그 외 특성을 추가해 2D-합성곱을 사용해도 된다. 최근 많이 시도되는 방법이 수치 데이터를 이미지 데이터로 변환한 후 분석하는 방법이 있다. CNN을 주가 데이터 예측에 사용하는 이유는 부분적 특성을 잡아내기 위함이다. 하지만 특성들은 잘 잡아내지만, 특성 사이 관계를 제대로 포착하기는 어려운 단점이 있다. 또 pooling을 적용하면 데이터 유실이 생겨 중요한 특성 데이터가 버려질 수 있다. 이는 기존 CNN모델에서 대두된 문제로, 이를 보완하기 위한 다양한 알고리즘들이 나오고 있다.(CapsNet 등)

##### RNN(Recurrent neural network, 순환 신경망)

앞서 CNN, 완전 연결 네트워크와 비교할 때 가장 큰 차이점은 '기억 시스템'이다. CNN이나 완전 연결 네트워크 같이 메모리가 없는 feed forward network는 입력 시퀀스를 하나의 데이터 포인트로 변환해야 하고 개별적으로 처리되어 이전 입력의 영향을 받지 않는다. 하지만 RNN은 학습 할 때 현재 입력값뿐만 아니라 이전 들어온 입력값도 고려하기 때문에 시계열 데이터를 학습하기에 적합하다. 신경망 중간에 있는 히든 레이어의 결과값들이 다시 입력값으로 들어가기 때문에 순환신경망이라는 이름이 붙었다.

그러나 RNN은 데이터가 너무 길어져 이를 표현하는 신경망이 깊어져야만 할 경우 문제가 된다. RNN은 역전파라는 방법을 통해 학습해, 위와 같이 gradient가 너무 작아져 학습이 잘 안 되는 문제가 발생한다. 이 문제를 해결하기 위해 LSTM이 만들어졌다. LSTM은 cell state라는 개념을 도입해서 그 내부에 있는 gate들을 통해 어떤 정보를 기억하고 어떤 정보를 버릴지 추가적인 학습을 가능하게 한다.

LSTM의 간소화 버전인 GRU도 많은 관심을 받고 있지만 아직 활용해 실험한 사례가 LSTM처러 많지 않다. SARIMA(주기성을 갖는 시계열 분석)모형에서는 데이터 과학자가 주기를 직접 입력해줘야 하지만, RNN 모델은 과거 패턴을 스스로 검출한다. 하지만 임의로 만든 직선이나 사인 곡선은 과거에 명백한 패턴이 있고 과거와 미래가 종속 관계에 있으므로 RNN이 학습할 수 있지만, 주가의 경우는 랜덤워크 성향으로 확실한 패턴이 없고 과거와 미래가 독립적이므로 RNN이 학습하기 어렵다.

이 말은 과거와 현재가 종속적이고 패턴을 보이는 데이터를 활용하면 예측이 가능하다는 뜻이기에, pair spread를 활용하는 방법이 있다. 이 두 주가의 차이를 이용하는 퀀트 방법인 pair trading을 차용한 것. 스프레드는 정상성을 갖는 시계열이고 과거와 현재의 종속성이 존재한다. 추가적으로 mean reverting(평균 회귀)특징까지 포함되어 퀀트에서 많이 활용되는 전략이다. 이외에도 많은 노이즈 제거 방법을 도입해 LSTM을 활용하는 시도가 늘고있다.

##### 비지도 학습

대표적인 알고리즘은 오토인코더가 있다. 오토인코더는 비지도 학습 알고리즘을 사용해 선형 관계와 비선형 관계를 표현할 수 있고, 이를 통해 잡은 제거에 탁월할 뿐 아니라 자료 분포 패턴 등을 추정할 수 있다는 장점이 있다. 학습과정에서 적은 수의 은닉 노드에 핵심 특성을 압축한 표현을 저장한다. 어떤 실험에서는 오토인코던의 이러한 특성을 이용해 기술적 분석 지표에 따른 주가 트렌드를 학습하고 예측에 반영한다. 물론 입력 데이터의 차원을 축소한다는 점에서 전통적인 머신러닝 차원 축소 방법인 PCA와 동일하지만, 오토인코더를 사용하면 인코더와 같은 일부 구성요소를 몇 개의 독립된 주식시장 수익률에 대해 각각 학습시킨 후 다른 네트워크에서 재사용할 수 있다는 장점이 있다.

##### 생성 모델

생성 모델이란 훈련 데이터가 주어졌ㅇㄹ 때 해당 데이터가 가지는 실제 분포와 같은 분포에서 샘플링된 값으로 새로운 데이터를 생성하는 모델을 말한다. 최근 GAN, VAE, RNN, 제한된 볼츠만 머신 등이 활발히 연구되고 있다. 

전통적인 머신러닝 방법에서는 은닉마르코프 모델(HMM)을 생성 모델로 사용. HMM은 많은 퀀트들에게 사랑받고, 르네상스 테크놀로지에서도 HMM을 활용해 초단기 시장에서 괄목할 성과를 올린 것으로 알려졌다. 

최근 이미지 생성 등 영역에서 뛰어난 성과를 보이는 GAN은 데이터 확장에도 많이 사용된다. 데이터 확장이란 비슷한 데이터를 만들어 다시 입력으로 활용하는 것. 딥러닝에서 주가 데이터를 예측할 때 가장 문제 되는게 데이터 부족인데 GAN이 이 문제를 해결해주리라 기대하고 있다. 하지만 실증적인 성과가 뚜렷이 있는게 아니라 아직은 연구 주제 정도로 시도해보는게 좋다.

그리고 주가 데이터 시뮬레이션 프로그램을 만들 대 예전에는 주로 기하 브라운 운동을 활용한 몬테카를로 시뮬레이션을 사용하곤 했는데, 이러한 작업에서도 이론상으로는 GAN의 할용이 가능해 졌다. GAN뿐만아니라 VAE를 사용한 모의 금융 시장 데이터 생성 작업이 활발하게 이루어지고 코드도 자유롭게 공유되고 있다.(https://mc.ai/generating-simulated-stock-price-data-using-a-variational-autoencoder/)

##### NLP(Natural language processing, 자연어 처리)

활용한 예로 영국의 한 회사가 트윗 분석을 통해 남다른 펀드 투자 성과를 이륙한 일이 대표적이다. NLP에서도 RNN, CNN, 강화학습 등의 알고리즘이 사용되므로, 투자전략을 개발하기 위해서는 NLP 전문가의 도움을 받아 유의미한 변수를 얻어 모델링에 활용하거나 직접 딥러닝 지식을 바탕으로 NLP영역에 도전해야 한다. 구글 트렌드나 트윗 데이터를 활용한 '감성분석(sentiment analysis)'을 투자 전략 개발에 적용한 예제는 인터넷에서도 쉽게 찾아볼 수 있어 참고 바란다.

#### 코드

머신러닝은 사이킷런을 사용한 것처럼, 딥러닝 알고리즘은 keras가 사용하기 좋다. Tensorflow, Pytorch, Keras가 점유율 순이다. 이 순위는 크게 신경 쓰이 않아도 되지만 코딩 능력이 좋다면 텐서플로를 사용해도 좋고, 더 뛰어나면 직접 파이썬을 구현해도 되고, 더 높은 경지에 이르면  C++로 직접 만들 수도 있다.

케라스는 사용자 친화적인 API로 딥러닝에 입문하는 사람에게 추천하는 프레임워크다. 반면 그만큼 자율성이 떨어진다. 그래서 딥러닝 과학자들은 파이토지를 더 선호하는 경향이 있다. 현업에서는 텐서플로, 파이토치, 케라스 모두 이용하게 될 확률이 높다. 





### 4.모델 평가 지표

#### -1.머신러닝 모델을 평가할 때 주의할 점

##### 1.트렌드에 대한 가중치

0.01%상승과 1%상승 데이터에 그대로 사용하면 똑같이 상승이라고 취급할 것이다. 비합리적이기에 상승률에 **가중치를 부여**하거나, 단순 이진 분류 문제를 **다중 분류 문제로 변환**하는 것이다. 어떻게 보면 데이터 전처리에 해당.

##### 2.레이블 데이터 불균형 문제

분류 문제로 주식시장의 방향성을 예측할 때 market regime에 따라 레이블 데이터 불균형이 발생할 수 있다. 정확도는 데이터 균형이 맞을 경우 뛰어난 성능을 보이지만, 불균형 데이터에서는 그렇지 않다. 따라서 AUC-ROC 점수 같은 측정 지표를 활용이 중요.

##### 3.다양한 지표 함께 보기

모델 성능 지표만으로는 실제 퀀트 전략을 구현하거나 상품화하는데 한계가 있다. 따라서 백테스트 결과에 대해 다각도로 고민해야 한다. 수익률은 산술평균보다 기하평균 수익률 활용이 바람직.

### 5.백테스팅

'백테스팅을 신뢰할 수 있는가'라는 주제는 금융계의 NP-hard 문제다. 지금으로선 전략의 유효성을 테스트할 방법이 과거 데이터에 의지하는 방법뿐이므로 최대한 백테스팅의 함정을 피해갈 테크닉을 사용해 신뢰성 있는 결과를 만들어내는게 중요.

* 최대한 많은 경제적 시나리오를 포함하는 백테스팅 기간 설정

백테스팅 기간을 보통 10년에서 길게는 30년까지 테스팅한다고 한다.

* 수수료와 슬리피지 고려

* 편향 고려

백테스팅에서 자주 발생하는 편향은 생존 편향/사전 관찰 편향/심리적 인내 편향이다. 생존편향은 중간에 상장 폐지된 종목들을 제외하고 진행하는 경우 발행. 사전 관찰 편향은 예로 3월의 GDP 지수를 4월말에 발표하는데 백테스팅에서는 이미 이를 알고 있다는 가정하에 사용하는 것이다. 심리적 인내 평향은 백테스팅 결과가 좋더라도 중간에 3~4개월 정도의 긴 기간 동안 지속적인 하락을 경험해야 한다면, 투자자는 견딜 수 없을지도 모른다. 환불이 늘어날 수 있기 때문에 다각도로 대고객 서비스를 살펴볼 필요가 있다.

* 특정 주가가 아닌 전체 자산 종류나 투자 영역에 대한 모델 개발하기

논란의 여지가 있지만, 특정 종목만을 예측하는 것보다 자산부류를 예측하는 것이 과적합을 조금이나마 줄일 수 있다. 이는 범용성이 뛰어난 모델을 개발하라는 의미가 아니다. 다양한 부류별 예측 모델을 개발하라는 것은, 모델 자체를 분산시켜 리스크를 줄여주는 효과를 준다. 한 전략에서 과적합 되더라도 다른 전략을 통해 상쇄하는 것이다. 이 부분은 전략을 만들고 결합하는 부분에서 다시 최적화해야 한다.

* 여러 가지 지표 활용하기

전략의 장단점을 파악하기 위해 수익률 외에 변동성, 샤프비율, MDD, 소르티노 지수, 트레이너 지수, 젠센의 알파 등 다양한 위험 및 성과지표를 살펴봐야 한다.

* 시계열 분석에 맞는 교차 검증 방법 활용하기

교차 검증 기법을 사용해 다양한 검증 진행 필요.

#### 종류

##### Zipline

##### QuantConnect

##### Quantiacs

시스템 트레이딩과 포트폴리오 최적화 기능을 쉽게 이용할 수 있도록 파이썬 라이브러리 지원. 

장점 : 클라우드 시스템 이용 가능 / 자신의 개발 전략 소유권 보장 / US Stock과 Commodities Futrures 종목에 대해 데이터 이용 가능 / 문서화가 잘 되어 있어 손쉽게 따라할 수 있다.

단점 : 실시간 트레이닝 지원되는지 확실지 않음.

##### Backtrader

개일 개발환경에서 백테스트를 하고 싶은 개발자에게 적합한 라이브러리. 데이터셋을 제공하지 않아 개별적으로 데이터셋을 구해야 하는 불편함이 있다. 하지만 공식 매뉴얼을 제공하며 서비스 이용료 부담 없이 라이브러리를 이용할 수 있는 장점이 있다. 또한 최근 깃허브에 소스코드 업데이트가 이루어지는 라이브러리 중 하나라서 지속적 유지보수가 된다는 큰 장점.

장점 : 외국의 일부 퀀트 회사들은 Backtrader를 백테스트 라이브러리로 사용 / 문서화가 잘 되어있다. / 실시간 트레이닝 지원 / 추가 비용이 없다 / 클라우드 서비스를 이용하지 않아도 된다. 즉, 개인 소스코드는 개인 소유물

단점 : 경재잉 없어 우승 상금 기회가 없다. / 개인적으로 데이터를 관리해야 한다.







## 5.트레이딩



# 참고문헌



퀀트 전략을 위한 인공지능 트레이닝

