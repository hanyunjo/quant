# 퀀트 개발

## 1.기본 개념

### 투자 성과 지표

* 연평균 복리수익률(CAGR)

  ![img](file:///C:\Users\enjon\AppData\Local\Temp\DRW0000455c2bbd.gif)  

* 최대 낙폭(MDD)

최대 낙폭 = (Trough Value - Peak Value) / Peak Value

* 변동성

  ![img](file:///C:\Users\enjon\AppData\Local\Temp\DRW0000455c2bc1.gif)  

* 샤프 지수

### 평균 회귀 전략

* 볼린저 밴드

### 듀얼 모멘텀 전략



### 가치 투자 전략





## 2.고급 개념





## 3.기본 개발

### 1.데이터 수집

#### 1.증권 API 이용

대신증권, 이베스트증권 등 몇개의 증권사에서만 제공.

github.com/quantylab/rltrader/blob/master/creon.py 참조

#### 2.웹 크롤링

1.google finance

pandas-datareader를 이용. but 안정적이지 않아 권장하지 않음.

2.yahoo finance

fix_yahoo_finance API 지원이 중단되면서 해당 API는 크롤링방식으로 변경해 제공

3.금융포털(investing.com/네이버 금융/yahoo finance 등)

해당 사이트 링크/robots.txt를 통해 크롤링 가능한 경로 확인.

많은 데이터를 가져오는데 제한적

4.데이터 요청

RLTrader Github에서 데이터 요청

#### 3.데이터 구매

#### 4.오픈 API 사용*

* FinanceDataReader : pandas-datareader의 불안정성을 보완하고자 만든 API

거래소별 전체 종목 코드 : StockListing()

가격데이터 : DataReader()

관련 API 사용자 메뉴얼 : https://github.com/FinanceData/FinanceDataReader/wiki/Users-Guide

~~~python
jp_df1 = fdr.DataReader(symbol='7751',start='2019-01-01',exchange='TSE')

jp_df1['Close'].plot()
~~~





![image-20211122145228175](C:\Users\enjon\AppData\Roaming\Typora\typora-user-images\image-20211122145228175.png)

거래소, 종목코드, 시작일 등 옵션을 주어 데이터를 불러와 그래프 그릴 수 있다.

### 2.데이터 가공 & 전처리

* 가공 : 필요한 영역만의 데이터 선택



* 결측치(NaN), 이상치(inf, 범위 초과 값...) 처리법

1.df[df.isin([np.nan, np.inf, -np.inf]).any(1)]

2.

3.

* 벡터화, 정규화, 특성 추출 등

* 전처리 과정에서 주의할 점

금융 데이터는 노이즈가 심하고 특성 수에 비해 상대적으로 시계열 데이터 길이가 짧다. 더 자세히 말하면, 일반적으로 주가 모델링은 기하 브라운 모형(GBM)을 가정하는데, 이는 자기 회귀 모형(AR)과 거의 동일하다. 내일의 주가를 영향을 미치는 요소가 오늘의 주가, 정보, 노이즈라 할 수 있는데 여기서 정보의 영향이 너무 작기 때문에 결과적으로 예측 모델을 이용하면 현재 값이 다음 값에 대한 최선의 예측값이 된다.

노이즈를 제거하는 전처리와 많은 변수의 타임 프레임을 맞추는 전처리 작업이 중요하다.

#### 노이즈 줄이는 법

노이즈 제거란 불필요한 데이터를 없애 중요한 정보에 주목하는 것 이다.

##### SVD(특이값 분해)

 흔히 정보 압축이나 차원 축소 방법 사용. 사실 노이즈 제거는 신호처리나 이미지 처리에서 많이 사용. 문제는 해당 분야에서 효과적인 노이즈 제거 방식은 금융 시계열에서는 큰 효과를 내지 못하는 경우가 많다. 그럼에도 노이즈 제거하기 위한 많은 방법이 시도되고 있다. 몇 가지를 소개하려 한다. 

##### 이동 평균과 지수 이동 평균

지수 이동 평균은 특정 기간의 주가 중 최근 가격에 더 큰 가중치를 두어 계산.

##### 웨이블릿 변환

웨이블릿 기저함수를 이용해 데이터를 변환하는 것을 말한다. 여기서 웨이블릿 기저함수는 적분하면 0이 되고 진동하면서 진폭이 0으로 수렴하는 함수를 말한다. 즉 웨이블릿이란 0을 중심으로 증가와 감소를 반복하는 파동과 같은 진동을 말한다. 웨이블릿 변환은 신호를 근사값과 세부값으로 구분한다. 근사값은 신호의 저주파 성분을 담고, 세부값은 신호의 고주파 성분을 담는다. 그리고 찾은 근사값을 다시 반으로 나눠 근사값과 세부값으로 구분한다. 이런 특징으로 웨이블릿은 데이터 압축에도 사용할 수 있다. 

##### PCA(주성분 분석)를 이용한 노이즈 제거

PCA는 여러 데이터가 모여 하나의 분포를 이룰 때 이 분포의 주성분을 분석하는 방법. 주성분이란 그 방향으로 데이터들의 분산이 가장 큰 방향 벡터를 의미한다. 즉 주성분만으로 충분히 표현 가능하기 때문에 부차적 요소를 제거할 수 있다는 장점이 있다. PCA 알고리즘은 PCA를 통해 반환된 각각의 주성분 해석하기 어려운 단점이 있어 해석력이 필요한 금융 데이터 분석에서는 권장하지 않는다.

##### 딥러닝 기반의 노이즈 제거 - 오토인코더

Autoencoder는 딥러닝에서 차원 축소할 때 기본적으로 사용하는 방법이다. 활성화 함수로 sigmoid,  ReLU같은 비선형 함수 대신 선형 함수를 사용하고, 손실 함수로 평균제곱오차(MSE)를 사용할 경우 PCA와 동일하다고 볼 수 있다. 다양한 적층 오토인코더(SAE)를 활용해 데이터의 노이즈를 제거하고 입력으로 사용해 좋은 성과를 냈다는 많은 논문과 자료를 확인할 수 있다. 



### +코드관련

모듈 : xxx.py같이 전역변수, 함수, 클래스 등을 모아둔 파일. 파일명이 곧 모듈명이다. 

패키지 : 모듈을 디렉토리 형식으로 묶어 놓은 것.





## 4.고급 개발

### 3-1.머신 러닝

#### 지도 학습

##### SVM(support vector machine)

하드웨어가 덜 발달 됐던 시절 딥러닝보다 성능이 좋았던 알고리즘.

* 장점

-데이터의 특성이 많지 않아도 상대적으로 좋은 성능을 낼 수 있다.

* 단점

데이터가 많을 시 속도, 메모리 관점에서 불리.

데이터 전처리와 매개변수 설정에 신경을 많이 써야 한다. 

해석 가능성이 약하다. 



#### 트리 기반 모델

##### Random forest(배깅계열)

  트리는 깊어질수록 편향이 작지만 분산이 커진다. 하지만 분산이 큰 각 트리의 평균을 취해주면 편향을 유지하면서 분산을 줄여 과적합을 보완한다. 중요한 것은 트리들의 상관관계를 줄여야 모델의 정확도가 높아진다는 것. 전처리 작업에서 상관계수가 높은 변수들을 걸러주는  것이 좋다. 

  일반적인 성능이 매우 뛰어나고, 매개변수 튜닝을 많이 하지 않아도 잘 작동하며 데이터의 스케일 조정이 필요 없다. CPU 코어가 많다면 병렬 처리도 손쉽게 할 수 있고, 특성 중요도를 계산할 수 있기 때문에 전략에 대한 해석 가능성을 높여준다. OOB(out-of-bags)데이터를 검증에 사용할 수 있다는 장점이 있지만, 주기성이나 경향성이 있는 데이터에서 선능이 떨어지는 경향이 있다. 또한 차원이 높고 희소한 데이터(예-텍스트 데이터)에는 잘 작동하지 않다.

  이런 단점에도 시장 데이터 예측이나 주가 종목 선택 문제에 많이 활용. 다양한 분류 알고리즘을 비교한 논문에도 랜덤 포레스트가 가장 좋은 성능을 언급. (Ballings, michel, et al. [Evaluating multiple cassifiers for stock price direction prediction.]) 그리고 주식 시장 예측 문제를 다룬 머신러닝 지도 학습 알고리즘을 분석한 논문에서는 랜덤 포레스트가 규모가 큰 데이터셋에서 가장 뛰어난 성능을 보인다는 결과를 내놓기도 했다.(Kumar, Indu, et al. [A comparative study of supervised machine learning algorithms for stock market trend prediction.]) 로페즈 교수는 PCA를 사용해 차원을 축소한 후 랜덤 포레스트에 적합하는 방법을 권장했다([Advances in financial machine learning]-John Wiley & Sons, 2018)

##### 부스팅(계열)

  약한 분류기를 결합해 강한 분류기를 만드는 과정을 일컫는다. 약한 분류기를 결합할 때 틀린 것에 가중치를 부여하며 강한 학습기를 만들어간다. 가중치를 부여하는 방식에 따라 분류 알고리즘이 달라진다. 그래디언트 부스팅 알고리즘(GBDT)는 경사 하강법을 사용한다. XGBoost, LightGBM이 이에 속한다.

  부스티 계열의 알고리즘은 테이블 형식의 데이터에서 매우 뛰어난 성능을 보여준다. XGBoost, LightGBM, CatBoost가 널리 쓰이고 있다. 

* 금융에서 부스팅과 배깅

부스팅은 오답에 높은 가중치를 부여하고 정답에 낮은 가중치를 부여해 오답에 더욱 집중하도록 하기 때문에 편향, 과소적합 문제를 훌륭하게 처리할 수 있는 장점이 있다.  그러나 편향을 교정하면 과적합을 일으킬 위험성이 커진다. 반면 배깅의 장점은 분산을 감소시킨다.

  금융데이터는 낮은 신호-노이즈 비율로 인해 모델을 과적합하는 일이 자주 일어나기 때문에 과적합은 과소적합보다 더 큰 문제가 될 수 있다. 따라서 금융에서는 부스팅보다 배깅계열을 더 선호한다는 주장이 있다. 또한 부스팅은 이상치에 취약하고 계산 속도가 배깅보다 더 느리다는 단점이 있다.

#### 비지도 학습

##### 차원 축소



##### 클러스터링



#### 교차 검증

다양한 방식들 존재. holdout 방법, one leave out 방법, k-fole 방법 등...

일반적으로 이러한 방법들은 시간적 요소가 포함된 시계열 데이터에 적합하지 않다는 의견이 많다. 시계열 데이터는 시간 축과 강한 상관관계를 가지는데 시간 축에는 명확한 순서가 있다. 202년 데이터를 사용해 훈련 후 18년 주가를 예측하는데 사용하면 안된다.사전 관찰 편향을 일으킬 수 있어 이를 해결하기 위해 다양한 방법중 일반적으로 walk-forward 교차 검증 방법이 있다.

##### walk-forward 교차 검증과 blocking walk forward 교차 검증

walk-forward 교차 검증은 사이킷런의 timesplit()함수로 쉽게 구현할 수 있다. 하지만 이 방식을 이용해도 데이터 leakage을 피할 수 없어 blocking walk-forward 교차 검증 방법을 사용하기도 한다. 이 방식은 margin을 설정한다.

> data leagkage란?  다시 정리하기**************
>
> target leakage와 train-test contamination이 있다.

* embargo & purging

train set과 test set 사이에 margin을 둬서, 각 검증 단계에서 사용하는 train set이 겹치지 않도록 설정한다. 하지만 시계열이 짧은 경우 좋은 성능을 내지 못할 확률이 크다. 많은 블로그에서 로페즈 교수가 자신의 책에서 소개한 purging, embargo를 접목한 교차 검증 방법이 많이 언급되나, 실증적으로 더 좋은 효과가 증명되지는 않았다. 이론적으로는 사전 관찰 편향을 피할 수 있지만, 아직 이 방법이 통용되지는 않는다. 

embargo방식은 test set 뒤에 더 넓은 margin을 추가해 leakage를 방지한다. 해당 교차 검증 방법은 mlfinlab이라는 라이브러리를 이용하면 쉽게 구현할 수 있다.

시계열데이터, 특히 금융 시계열에서 좋은 성능을 낼 수 있는 교차 검증 방법은 heuristic하게 여러가지를 시도하는 수밖에 없다. 교차 검증 목적은 우리가 훈련시킨 모델이 일반화 능력을 가질 수 있게 만드는 것이다. 하지만 데이터 자체에 노이즈가 많거나 입력으로 사용한 변수가 유용하지 못하면 아무리 좋은 교차 검증 방법을 사용해도 신뢰할 만한 결과를 얻기 힘들다.





###  3-2.Deep learning

부스팅 계열 알고리즘에 해당.



### 4.모델 평가 지표

#### 머신러닝 모델을 평가할 때 주의할 점

##### 1.트렌드에 대한 가중치

0.01%상승과 1%상승 데이터에 그대로 사용하면 똑같이 상승이라고 취급할 것이다. 비합리적이기에 상승률에 **가중치를 부여**하거나, 단순 이진 분류 문제를 **다중 분류 문제로 변환**하는 것이다. 어떻게 보면 데이터 전처리에 해당.

##### 2.레이블 데이터 불균형 문제

분류 문제로 주식시장의 방향성을 예측할 때 market regime에 따라 레이블 데이터 불균형이 발생할 수 있다. 정확도는 데이터 균형이 맞을 경우 뛰어난 성능을 보이지만, 불균형 데이터에서는 그렇지 않다. 따라서 AUC-ROC 점수 같은 측정 지표를 활용이 중요.

##### 3.다양한 지표 함께 보기

모델 성능 지표만으로는 실제 퀀트 전략을 구현하거나 상품화하는데 한계가 있다. 따라서 백테스트 결과에 대해 다각도로 고민해야 한다. 수익률은 산술평균보다 기하평균 수익률 활용이 바람직.

### 5.백테스팅

'백테스팅을 신뢰할 수 있는가'라는 주제는 금융계의 NP-hard 문제다. 지금으로선 전략의 유효성을 테스트할 방법이 과거 데이터에 의지하는 방법뿐이므로 최대한 백테스팅의 함정을 피해갈 테크닉을 사용해 신뢰성 있는 결과를 만들어내는게 중요.









## 5.트레이딩



# 참고문헌



퀀트 전략을 위한 인공지능 트레이닝

